model:
  base_learning_rate: 1.0e-03
  target: gldm.latent_diffusion.ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: image
    # cond_stage_key: gene_expressions
    image_size: 512
    channels: 1
    # cond_stage_trainable: False
    # conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 1 #0.18215
    use_ema: False
    parameterization: eps

    scheduler_config: # 10000 warmup steps
      target: gldm.latent_diffusion.ldm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps: [10000]
        cycle_lengths: [10000000000000]
        f_start: [1.e-6]
        f_max: [1.]
        f_min: [ 1.]

  first_stage_config:
    target: gldm.autoencoder.aae.AAE
    model_type: wae
    using_lincs: False
    using_wasserstein_loss: True
    using_gp: True
    ckpt_path: first_stage_models/WAE_uncond.pt
  
  cond_stage_config: __is_unconditional__

  unet_config:
    target: gldm.latent_diffusion.ldm.modules.diffusionmodules.openaimodel.UNetModel
    params:
      # use_spatial_transformer: true
      image_size: 512
      in_channels: 1
      out_channels: 1
      model_channels: 64
      dims: 1 
      attention_resolutions:
      # note: this isn\t actually the resolution but
      # the downsampling factor, i.e. this corresnponds to
      # attention on spatial resolution 8,16,32, as the
      # spatial reolution of the latents is 64 for f4
      - 4
      - 2
      num_res_blocks: 1
      channel_mult:
      - 1
      - 2
      - 3
      # context_dim: 979
      num_head_channels: 8